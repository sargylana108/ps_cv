{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4833d19f-8005-4b98-abb3-ca8b19247c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagi\\AppData\\Local\\Temp\\ipykernel_11048\\4072693634.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import laspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset, Sampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import KDTree\n",
    "from torch_geometric.nn import knn_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4113e06f-1626-4b88-98b8-39ebf6195e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "# Параметры\n",
    "TRAIN_DIR = r\"G:/tmp/powersafe/power-line-security-zone-vegetation-detection/train/train/\"\n",
    "TRAIN_CSV = r\"G:/tmp/powersafe/power-line-security-zone-vegetation-detection/train.csv\"\n",
    "TEST_DIR = r\"G:/tmp/powersafe/power-line-security-zone-vegetation-detection/test/test/\"\n",
    "OUTPUT_CSV = \"predictions.csv\"\n",
    "META_CSV = \"metafile.csv\"\n",
    "PREPROCESS_DIR = 'preprocessed_data_all_01'\n",
    "NUM_POINTS = 1024\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_WORKERS = 2\n",
    "NUM_CLASSES = 3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используется устройство: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c29a54-a79e-4a9c-897d-e8ec9c88e39e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aca43a8-bfa8-4a9d-94c2-0263c19b307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример данных из train.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>center_z</th>\n",
       "      <th>size_x</th>\n",
       "      <th>size_y</th>\n",
       "      <th>size_z</th>\n",
       "      <th>yaw</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z3_cloud0.las</td>\n",
       "      <td>-663.347102</td>\n",
       "      <td>-1460.27430</td>\n",
       "      <td>18.188135</td>\n",
       "      <td>3.337630</td>\n",
       "      <td>7.925643</td>\n",
       "      <td>27.058957</td>\n",
       "      <td>-1.078151</td>\n",
       "      <td>LEP_metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z3_cloud0.las</td>\n",
       "      <td>-634.749750</td>\n",
       "      <td>-1405.22530</td>\n",
       "      <td>4.103850</td>\n",
       "      <td>4.792479</td>\n",
       "      <td>6.259897</td>\n",
       "      <td>2.624300</td>\n",
       "      <td>-1.272828</td>\n",
       "      <td>vegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z3_cloud0.las</td>\n",
       "      <td>-607.369550</td>\n",
       "      <td>-1409.58785</td>\n",
       "      <td>3.319400</td>\n",
       "      <td>4.708849</td>\n",
       "      <td>3.992601</td>\n",
       "      <td>2.291600</td>\n",
       "      <td>-2.455875</td>\n",
       "      <td>vegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z3_cloud0.las</td>\n",
       "      <td>-649.871550</td>\n",
       "      <td>-1396.08245</td>\n",
       "      <td>5.343050</td>\n",
       "      <td>3.506985</td>\n",
       "      <td>3.801660</td>\n",
       "      <td>3.635700</td>\n",
       "      <td>-2.056539</td>\n",
       "      <td>vegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z3_cloud0.las</td>\n",
       "      <td>-632.809100</td>\n",
       "      <td>-1398.19915</td>\n",
       "      <td>5.876200</td>\n",
       "      <td>2.742089</td>\n",
       "      <td>2.520110</td>\n",
       "      <td>4.055600</td>\n",
       "      <td>-1.515782</td>\n",
       "      <td>vegetation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name    center_x    center_y   center_z    size_x    size_y  \\\n",
       "0  Z3_cloud0.las -663.347102 -1460.27430  18.188135  3.337630  7.925643   \n",
       "1  Z3_cloud0.las -634.749750 -1405.22530   4.103850  4.792479  6.259897   \n",
       "2  Z3_cloud0.las -607.369550 -1409.58785   3.319400  4.708849  3.992601   \n",
       "3  Z3_cloud0.las -649.871550 -1396.08245   5.343050  3.506985  3.801660   \n",
       "4  Z3_cloud0.las -632.809100 -1398.19915   5.876200  2.742089  2.520110   \n",
       "\n",
       "      size_z       yaw       class  \n",
       "0  27.058957 -1.078151   LEP_metal  \n",
       "1   2.624300 -1.272828  vegetation  \n",
       "2   2.291600 -2.455875  vegetation  \n",
       "3   3.635700 -2.056539  vegetation  \n",
       "4   4.055600 -1.515782  vegetation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка обучающих данных\n",
    "train_labels = pd.read_csv(TRAIN_CSV)\n",
    "print(\"Пример данных из train.csv:\")\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8eb6e14-09cd-48cb-a237-17108317f6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов в train.csv:\n",
      "class\n",
      "vegetation    4309\n",
      "LEP_prom       305\n",
      "LEP_metal      262\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Анализ распределения классов\n",
    "class_counts = train_labels['class'].value_counts()\n",
    "print(\"Распределение классов в train.csv:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c446ad08-e346-4778-a1fc-a3de36c92c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Отображение распределения классов\n",
    "labels_counter = Counter(train_labels['class'])\n",
    "class_names = list(labels_counter.keys())\n",
    "class_counts = list(labels_counter.values())\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.bar(class_names, class_counts)\n",
    "plt.xlabel('Названия классов')\n",
    "plt.ylabel('Количество образцов')\n",
    "plt.title('Распределение классов в датасете')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee23058-19b9-490c-971b-5b56041dec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: ['LEP_metal' 'LEP_prom' 'vegetation']\n",
      "Количество классов: 3\n"
     ]
    }
   ],
   "source": [
    "# Преобразование меток в числа\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels['encoded_class'] = label_encoder.fit_transform(train_labels['class'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Классы: {label_encoder.classes_}\")\n",
    "print(f\"Количество классов: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a483f-913b-431a-9d0a-26abf2a7e8c5",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7e07fc-c15c-400b-9a05-510d9b82cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_points_from_bounding_box(las_file_path, bbox):\n",
    "    \"\"\"\n",
    "    Извлекает точки из LAS файла, попадающие внутрь bounding-box с учетом yaw.\n",
    "    \n",
    "    Parameters:\n",
    "        las_file_path (str): Путь к LAS файлу.\n",
    "        bbox (dict): Bounding-box с координатами, размерами и yaw.\n",
    "                     {'center_x', 'center_y', 'center_z', 'size_x', 'size_y', 'size_z', 'yaw'}\n",
    "    Returns:\n",
    "        np.ndarray: Точки внутри bounding-box в формате [X, Y, Z].\n",
    "    \"\"\"\n",
    "    # Открываем файл\n",
    "    las = laspy.read(las_file_path)\n",
    "    \n",
    "    # Преобразуем координаты в локальную систему\n",
    "    x_global, y_global, z_global = las.x, las.y, las.z\n",
    "    x_local = x_global - las.header.offsets[0]\n",
    "    y_local = y_global - las.header.offsets[1]\n",
    "    z_local = z_global - las.header.offsets[2]\n",
    "\n",
    "    # Перемещаем точки в центр bounding-box\n",
    "    x_local -= bbox[\"center_x\"]\n",
    "    y_local -= bbox[\"center_y\"]\n",
    "    z_local -= bbox[\"center_z\"]\n",
    "\n",
    "    # Поворачиваем точки на угол -yaw (чтобы выровнять bounding-box по осям)\n",
    "    yaw = -bbox[\"yaw\"]\n",
    "    cos_yaw = np.cos(yaw)\n",
    "    sin_yaw = np.sin(yaw)\n",
    "    x_rotated = cos_yaw * x_local - sin_yaw * y_local\n",
    "    y_rotated = sin_yaw * x_local + cos_yaw * y_local\n",
    "\n",
    "    # Вычисляем границы bounding-box в повернутой системе координат\n",
    "    min_x = -bbox[\"size_x\"] / 2\n",
    "    max_x = bbox[\"size_x\"] / 2\n",
    "    min_y = -bbox[\"size_y\"] / 2\n",
    "    max_y = bbox[\"size_y\"] / 2\n",
    "    min_z = -bbox[\"size_z\"] / 2\n",
    "    max_z = bbox[\"size_z\"] / 2\n",
    "\n",
    "    # Фильтруем точки, попадающие в bounding-box\n",
    "    mask = (\n",
    "        (x_rotated >= min_x) & (x_rotated <= max_x) &\n",
    "        (y_rotated >= min_y) & (y_rotated <= max_y) &\n",
    "        (z_local >= min_z) & (z_local <= max_z)\n",
    "    )\n",
    "    points = np.vstack((x_global[mask], y_global[mask], z_global[mask])).T\n",
    "    return points\n",
    "\n",
    "\n",
    "def process_las_files_in_parallel(train_labels, train_dir, output_dir, n_jobs=4):\n",
    "    \"\"\"\n",
    "    Обрабатывает все LAS файлы, извлекая bounding-box данные из train_labels.\n",
    "    \n",
    "    Parameters:\n",
    "        train_labels (pd.DataFrame): Метки данных с bounding-box.\n",
    "        train_dir (str): Папка с LAS файлами.\n",
    "        output_dir (str): Папка для сохранения предобработанных данных.\n",
    "        n_jobs (int): Количество потоков для параллельной обработки.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def process_single_file(file_name):\n",
    "        las_file_path = os.path.join(train_dir, file_name)\n",
    "        bboxes = train_labels[train_labels['file_name'] == file_name]\n",
    "        metadata = []  # Список для метаинформации файлов\n",
    "        for idx, row in bboxes.iterrows():\n",
    "            output_file = os.path.join(output_dir, f\"{file_name}_{idx}_{row['class']}.npy\")\n",
    "            # Если файл уже существует, пропускаем\n",
    "            if os.path.exists(output_file):\n",
    "                continue\n",
    "            \n",
    "            bbox = {\n",
    "                \"center_x\": row[\"center_x\"],\n",
    "                \"center_y\": row[\"center_y\"],\n",
    "                \"center_z\": row[\"center_z\"],\n",
    "                \"size_x\": row[\"size_x\"],\n",
    "                \"size_y\": row[\"size_y\"],\n",
    "                \"size_z\": row[\"size_z\"],\n",
    "                \"yaw\": row[\"yaw\"],\n",
    "            }\n",
    "            points = extract_points_from_bounding_box(las_file_path, bbox)\n",
    "            np.save(output_file, points)\n",
    "            \n",
    "            # Добавляем запись о метаинформации\n",
    "            metadata.append({\n",
    "                \"file_name\": output_file,\n",
    "                \"class\": row[\"class\"],\n",
    "                \"bbox_id\": idx\n",
    "            })\n",
    "        \n",
    "        # Сохраняем метаинформацию в CSV\n",
    "        metadata_file = os.path.join(output_dir, META_CSV)\n",
    "        metadata_df = pd.DataFrame(metadata)\n",
    "        if os.path.exists(metadata_file):\n",
    "            # Дополняем существующий CSV\n",
    "            metadata_df.to_csv(metadata_file, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # Создаем новый CSV\n",
    "            metadata_df.to_csv(metadata_file, index=False)\n",
    "        return f\"Processed {file_name}\"\n",
    "    \n",
    "    # Получаем список уникальных файлов\n",
    "    unique_files = train_labels['file_name'].unique()\n",
    "    \n",
    "    # Обрабатываем файлы параллельно\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_single_file)(file_name) for file_name in tqdm(unique_files)\n",
    "    )\n",
    "    print(\"\\n\".join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6357d04-644c-4c58-b1b6-5b6b19be9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предварительная обработка\n",
    "# processed_files = process_las_files_in_parallel(train_labels, TRAIN_DIR, PREPROCESS_DIR, n_jobs=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30991c12-4a1b-4722-8aa6-42ec8a2b9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуальная проверка \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualize_points(points):\n",
    "    \"\"\"\n",
    "    Визуализирует 3D точки.\n",
    "    \n",
    "    Parameters:\n",
    "        points (np.ndarray): Массив точек в формате [X, Y, Z].\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=1, c='blue')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.show()\n",
    "\n",
    "# Пример визуализации первых данных\n",
    "example_file = os.path.join(PREPROCESS_DIR, os.listdir(PREPROCESS_DIR)[38])\n",
    "example_points = np.load(example_file)\n",
    "visualize_points(example_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b47ade-7ead-448b-97d3-10f5e92787c5",
   "metadata": {},
   "source": [
    "# Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13e45316-6b73-457b-b846-f79a6f3a90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датасет\n",
    "class PointCloudDatasetFromNpy(Dataset):\n",
    "    def __init__(self, data_dir, num_points=1024, label_encoder=None):\n",
    "        \"\"\"\n",
    "        Инициализация датасета.\n",
    "\n",
    "        Parameters:\n",
    "            data_dir (str): Директория с файлами .npy.\n",
    "            num_points (int): Количество точек, которые будут использоваться для выборки из каждого файла.\n",
    "            label_encoder (LabelEncoder): Кодировщик для классов. Если None, будет создан новый.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.num_points = num_points\n",
    "        self.file_names = [f for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
    "\n",
    "        # Извлекаем метки классов из имен файлов\n",
    "        self.labels = [self._extract_label_from_filename(f) for f in self.file_names]\n",
    "\n",
    "        # Кодируем классы\n",
    "        if label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            self.labels_encoded = self.label_encoder.fit_transform(self.labels)\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "            self.labels_encoded = self.label_encoder.transform(self.labels)\n",
    "\n",
    "    def _extract_label_from_filename(self, filename):\n",
    "        \"\"\"\n",
    "        Извлекает класс из имени файла с использованием регулярного выражения.\n",
    "\n",
    "        Parameters:\n",
    "            filename (str): Имя файла (например, 'Day1_0_LEP_metal.npy').\n",
    "\n",
    "        Returns:\n",
    "            str: Название класса ('LEP_metal', 'LEP_prom', или 'vegetation').\n",
    "        \"\"\"\n",
    "        # Регулярное выражение для поиска допустимых меток\n",
    "        match = re.search(r'(LEP_metal|LEP_prom|vegetation)', filename)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise ValueError(f\"Не удалось извлечь класс из имени файла: {filename}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Загружаем точки из файла\n",
    "        file_path = os.path.join(self.data_dir, self.file_names[idx])\n",
    "        points = np.load(file_path)\n",
    "\n",
    "        # Случайная выборка точек\n",
    "        if len(points) >= self.num_points:\n",
    "            indices = np.random.choice(len(points), self.num_points, replace=False)\n",
    "        else:\n",
    "            indices = np.random.choice(len(points), self.num_points, replace=True)\n",
    "        points_sampled = points[indices]\n",
    "\n",
    "        # Нормализация точек\n",
    "        points_sampled = points_sampled - np.mean(points_sampled, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points_sampled, axis=1))\n",
    "        if scale > 0:\n",
    "            points_sampled = points_sampled / scale\n",
    "\n",
    "        # Получаем закодированную метку\n",
    "        label = self.labels_encoded[idx]\n",
    "        return torch.tensor(points_sampled, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Аугментация\n",
    "class PointCloudAugmentation:\n",
    "    @staticmethod\n",
    "    def random_shift(points):\n",
    "        shift = np.random.uniform(-0.1, 0.1, size=(1, 3))  # уменьшили диапазон\n",
    "        return points + shift\n",
    "\n",
    "    @staticmethod\n",
    "    def random_scale(points):\n",
    "        scale = np.random.uniform(0.9, 1.1)  # уменьшили диапазон масштабирования\n",
    "        return points * scale\n",
    "\n",
    "    @staticmethod\n",
    "    def random_jitter(points, sigma=0.005, clip=0.02):  # уменьшили уровень шума\n",
    "        jitter = np.clip(sigma * np.random.randn(*points.shape), -clip, clip)\n",
    "        return points + jitter\n",
    "\n",
    "    def __call__(self, points):\n",
    "        points = self.random_shift(points)\n",
    "        points = self.random_scale(points)\n",
    "        points = self.random_jitter(points)\n",
    "        return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c318f3e-2f22-442c-8957-371b521628d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасета\n",
    "dataset = PointCloudDatasetFromNpy(data_dir=PREPROCESS_DIR, num_points=NUM_POINTS)\n",
    "\n",
    "# Проверка классов\n",
    "print(np.unique(dataset.labels))\n",
    "print(dataset.label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f1270-8139-45ef-965f-1e92f7f921f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на обучающую и валидационную выборки\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    stratify=dataset.labels_encoded\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {len(train_dataset)}\")\n",
    "print(f\"Размер валидационной выборки: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65646beb-e005-4616-908e-4bb4d6a0a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Балансировка классов\n",
    "train_labels = [train_dataset.dataset[idx][1] for idx in train_dataset.indices]\n",
    "train_labels = np.array(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=np.arange(NUM_CLASSES), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "criterion = nn.NLLLoss(weight=class_weights)\n",
    "\n",
    "# Создаем WeightedRandomSampler для балансировки\n",
    "class_counts = np.bincount(train_labels)\n",
    "weights = 1.0 / class_counts\n",
    "sample_weights = weights[train_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb1467-498d-412f-becf-cf3dddf47d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание даталоадеров \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10547f9-72c5-48d9-8dc5-3638793525f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "points, labels = next(iter(train_loader))\n",
    "print(f\"Размер точек: {points.shape}, Метки: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138e365-e67f-4448-8c88-3cc9ceca8a90",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aacb98f6-bc37-46b1-8eae-1f02571a83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая PointNet\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # Применение сверточных слоев с BatchNorm и ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # [batch_size, 64, num_points]\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # [batch_size, 128, num_points]\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # [batch_size, 1024, num_points]\n",
    "\n",
    "        # Глобальный max pooling по точкам\n",
    "        x = torch.max(x, 2)[0]  # [batch_size, 1024]\n",
    "\n",
    "        # Полносвязные слои с BatchNorm, ReLU и Dropout\n",
    "        x = F.relu(self.bn4(self.fc1(x)))  # [batch_size, 512]\n",
    "        x = F.relu(self.bn5(self.fc2(x)))  # [batch_size, 256]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Выходной слой\n",
    "        x = self.fc3(x) \n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3283a712-8607-4973-b9d1-a9557be42d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PointNet++ с трансформером\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual Block для выделения локальных признаков.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.shortcut = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)  # Сохранение входного значения\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        return F.relu(x + shortcut)  # Добавление остаточного соединения\n",
    "        \n",
    "\n",
    "class DGCNNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    DGCNN Layer для извлечения локальных признаков на основе графа.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, k=5):\n",
    "        super(DGCNNLayer, self).__init__()\n",
    "        self.k = k  # Число соседей\n",
    "        self.conv = nn.Conv2d(in_channels * 2, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_points, num_features = x.size()\n",
    "\n",
    "        # Вычисление попарных расстояний\n",
    "        inner = -2 * torch.matmul(x, x.transpose(2, 1))\n",
    "        xx = torch.sum(x ** 2, dim=-1, keepdim=True)\n",
    "        pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
    "\n",
    "        # Поиск k ближайших соседей\n",
    "        _, idx = torch.topk(pairwise_distance, self.k, dim=-1)\n",
    "\n",
    "        # Извлечение признаков соседей\n",
    "        idx = idx.unsqueeze(-1).expand(-1, -1, -1, num_features)\n",
    "        neighbors = torch.gather(x.unsqueeze(1).expand(-1, num_points, -1, -1), 2, idx)\n",
    "        central_points = x.unsqueeze(2).expand(-1, -1, self.k, -1)\n",
    "        edge_features = torch.cat([central_points, neighbors - central_points], dim=-1)\n",
    "\n",
    "        # Преобразование для Conv2d\n",
    "        x = edge_features.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Применение свертки\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "        # Агрегация признаков (максимум по соседям)\n",
    "        return torch.max(x, dim=-1)[0]\n",
    "\n",
    "class AttentionModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Module для выделения наиболее важных признаков.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv1d(channels, channels // 16, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(channels // 16, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_weights = self.attn(x)\n",
    "        return x * attn_weights\n",
    "\n",
    "\n",
    "class GlobalAggregation(nn.Module):\n",
    "    \"\"\"\n",
    "    Global Aggregation для объединения глобальных признаков со всех точек.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GlobalAggregation, self).__init__()\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        max_pool = self.max_pool(x).squeeze(-1)\n",
    "        avg_pool = self.avg_pool(x).squeeze(-1)\n",
    "        sum_pool = torch.sum(x, dim=2)\n",
    "        return torch.cat([max_pool, avg_pool, sum_pool], dim=1)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Block для захвата глобальных связей между признаками.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=1024, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2)  # [num_points, batch_size, d_model]\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        ff_output = self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x.permute(1, 0, 2)  # [batch_size, num_points, d_model]\n",
    "        \n",
    "\n",
    "class PointNetPlusPlusTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Основная модель PointNet++ с трансформером для обработки облаков точек.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, input_channels=3):\n",
    "        super(PointNetPlusPlusTransformer, self).__init__()\n",
    "\n",
    "        # Блоки выделения локальных признаков\n",
    "        self.sa1 = ResidualBlock(input_channels, 64)\n",
    "        self.sa2 = ResidualBlock(64, 128)\n",
    "        self.sa3 = ResidualBlock(128, 256)\n",
    "        self.dgcnn = DGCNNLayer(256, 256, k=5)\n",
    "\n",
    "        # Глобальная агрегация\n",
    "        self.global_conv = nn.Conv1d(256, 1024, 1)\n",
    "        self.global_bn = nn.BatchNorm1d(1024)\n",
    "        self.global_agg = GlobalAggregation()\n",
    "\n",
    "        # Трансформер и внимание\n",
    "        self.transformer = TransformerBlock(d_model=3072, nhead=4, dim_feedforward=1024, dropout=0.1)\n",
    "        self.global_attn = AttentionModule(3072)\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(3072, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Обработка через слои выделения признаков\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, num_points, channels]\n",
    "        x = self.sa1(x)\n",
    "        x = self.sa2(x)\n",
    "        x = self.sa3(x)\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, channels, num_points]\n",
    "        x = self.dgcnn(x)\n",
    "\n",
    "        # Глобальная агрегация\n",
    "        x = F.relu(self.global_bn(self.global_conv(x)))\n",
    "        x = self.global_agg(x)\n",
    "\n",
    "        # Обработка через трансформер\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        # Применение внимания\n",
    "        x = self.global_attn(x.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e879d-be20-4102-ad84-2fd793ba0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация модели\n",
    "augmenter = PointCloudAugmentation()\n",
    "model = PointNetPlusPlusTransformer(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=100, mode='triangular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff129775-1840-4ca8-914a-0365ca843780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "points, labels = next(iter(train_loader))\n",
    "print(\"Размерность точек:\", points.shape)  # (batch_size, num_points, 3)\n",
    "print(\"Размерность меток:\", labels.shape)  # (batch_size,)\n",
    "print(\"Образцы точек:\", points[0])\n",
    "print(\"Образец метки:\", labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f4a13-0b73-468e-af4a-1d5fc873e9f5",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b359ee-a0cd-4cbd-9495-15d4212b0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_map(predictions, ground_truths, max_distance=5, num_classes=3):\n",
    "    \"\"\"\n",
    "    Вычисление Mean Average Precision (mAP) с использованием KDTree для ускорения.\n",
    "\n",
    "    Args:\n",
    "        predictions: Список предсказаний.\n",
    "        ground_truths: Список истинных меток.\n",
    "        max_distance: Максимальное расстояние для учета как TP.\n",
    "        num_classes: Количество классов.\n",
    "\n",
    "    Returns:\n",
    "        mAP: Значение Mean Average Precision.\n",
    "    \"\"\"\n",
    "    aps = []\n",
    "    for cls in range(num_classes):\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        gt_matched = set()\n",
    "\n",
    "        pred_cls = [p for p in predictions if p['class'] == cls]\n",
    "        gt_cls = [g for g in ground_truths if g['class'] == cls]\n",
    "\n",
    "        if len(gt_cls) > 0:\n",
    "            gt_centers = np.array([[g['center_x'], g['center_y'], g['center_z']] for g in gt_cls])\n",
    "            tree = KDTree(gt_centers)\n",
    "        else:\n",
    "            tree = None\n",
    "\n",
    "        for pred in pred_cls:\n",
    "            pred_center = np.array([pred['center_x'], pred['center_y'], pred['center_z']])\n",
    "            pred_score = pred['score']\n",
    "            y_scores.append(pred_score)\n",
    "\n",
    "            if tree is not None:\n",
    "                dist, idx = tree.query(pred_center, distance_upper_bound=max_distance)\n",
    "                if dist <= max_distance and idx not in gt_matched:\n",
    "                    y_true.append(1)\n",
    "                    gt_matched.add(idx)\n",
    "                else:\n",
    "                    y_true.append(0)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "        if len(y_true) == 0:\n",
    "            y_scores = [0] * len(pred_cls)\n",
    "\n",
    "        if len(y_true) > 0 and len(y_scores) > 0:\n",
    "            ap = average_precision_score(y_true, y_scores)\n",
    "            aps.append(ap)\n",
    "        else:\n",
    "            aps.append(0)\n",
    "\n",
    "    return np.mean(aps) if len(aps) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ed9c9-4c00-41f3-a5be-23f1120eb36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Цикл обучения\n",
    "best_val_map = 0.0\n",
    "early_stopping_patience = 15  # Количество эпох для EarlyStop\n",
    "patience_counter = 0\n",
    "\n",
    "augmenter = PointCloudAugmentation()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    # === ТРЕНИРОВОЧНЫЙ ЭТАП ===\n",
    "    for points, labels in tqdm(train_loader, desc=f\"Эпоха {epoch+1}/{NUM_EPOCHS}\", leave=False):\n",
    "        # Аугментация данных\n",
    "        points = points.numpy()\n",
    "        points = np.array([augmenter(p) for p in points])\n",
    "        points = torch.tensor(points, dtype=torch.float32)\n",
    "\n",
    "        points, labels = points.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(points)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f\"Эпоха {epoch+1}/{NUM_EPOCHS}: Потеря (train): {avg_loss:.4f}, Точность (train): {train_accuracy:.2f}%\")\n",
    "\n",
    "    # === ВАЛИДАЦИОННЫЙ ЭТАП ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for points, labels in tqdm(val_loader, desc=\"Валидация\"):\n",
    "            points, labels = points.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(points)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Сохранение предсказаний и истинных меток для расчета mAP\n",
    "            for i in range(labels.size(0)):\n",
    "                yaw = calculate_yaw(points[i].cpu().numpy())\n",
    "                predictions.append({\n",
    "                    'class': predicted[i].item(),\n",
    "                    'center_x': points[i][:, 0].mean().item(),\n",
    "                    'center_y': points[i][:, 1].mean().item(),\n",
    "                    'center_z': points[i][:, 2].mean().item(),\n",
    "                    'yaw': yaw,\n",
    "                    'score': torch.exp(outputs[i, predicted[i]]).item()\n",
    "                })\n",
    "                ground_truths.append({\n",
    "                    'class': labels[i].item(),\n",
    "                    'center_x': points[i][:, 0].mean().item(),\n",
    "                    'center_y': points[i][:, 1].mean().item(),\n",
    "                    'center_z': points[i][:, 2].mean().item()\n",
    "                })\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    val_map = compute_map(predictions, ground_truths, max_distance=5, num_classes=NUM_CLASSES)\n",
    "\n",
    "    print(f\"Эпоха {epoch+1}/{NUM_EPOCHS}: Валидация — Потеря: {avg_val_loss:.4f}, Точность: {val_accuracy:.2f}%, mAP: {val_map:.4f}\")\n",
    "\n",
    "    # === СОХРАНЕНИЕ ЛУЧШЕЙ МОДЕЛИ ===\n",
    "    if val_map > best_val_map:\n",
    "        best_val_map = val_map\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), f'PointNetPP_epoch_{epoch+1}.pth')\n",
    "        print(f\"Сохранена модель с mAP {best_val_map:.4f}.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # === ПРОВЕРКА НА EARLY STOPPING ===\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Досрочная остановка обучения из-за отсутствия улучшений.\")\n",
    "        break\n",
    "\n",
    "print(f\"Обучение завершено. Лучшая mAP: {best_val_map:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0e00a-db2e-4bcd-aea3-49c7e25240f9",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13fbf409-1daf-4524-861d-c97bec7b6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчёт угла поворота\n",
    "def calculate_yaw(points):\n",
    "    if len(points) > 1:\n",
    "        vector = points[-1, :2] - points[0, :2]\n",
    "        yaw = np.arctan2(vector[1], vector[0])\n",
    "    else:\n",
    "        yaw = 0.0\n",
    "    return yaw\n",
    "\n",
    "# Обработка ячеек батчами\n",
    "def process_cells_in_batch(cell_points_dict, file_name, label_encoder, score_threshold, model, device, num_points):\n",
    "    batch_points = []\n",
    "    batch_indices = []\n",
    "\n",
    "    # Формируем батчи для параллельного предсказания\n",
    "    for idx, cell_points in cell_points_dict.items():\n",
    "        cell_points = np.array(cell_points)\n",
    "        num_cell_points = len(cell_points)\n",
    "\n",
    "        if num_cell_points >= num_points:\n",
    "            # Случайная выборка num_points точек\n",
    "            selected_indices = np.random.choice(num_cell_points, num_points, replace=False)\n",
    "            cell_points_sampled = cell_points[selected_indices]\n",
    "        else:\n",
    "            continue  # Пропускаем ячейки с недостаточным количеством точек\n",
    "\n",
    "        # Вычисление центра ячейки и нормализация точек\n",
    "        center_local = np.mean(cell_points_sampled, axis=0)\n",
    "        cell_points_centered = cell_points_sampled - center_local\n",
    "        scale = np.max(np.linalg.norm(cell_points_centered, axis=1))\n",
    "        if scale > 0:\n",
    "            cell_points_normalized = cell_points_centered / scale\n",
    "        else:\n",
    "            cell_points_normalized = cell_points_centered\n",
    "\n",
    "        batch_points.append(cell_points_normalized)\n",
    "        batch_indices.append((idx, center_local, cell_points_sampled))\n",
    "\n",
    "    if not batch_points:\n",
    "        return []\n",
    "\n",
    "    # Преобразование в тензор и выполнение предсказания модели\n",
    "    batch_points = np.array(batch_points)\n",
    "    batch_tensor = torch.tensor(batch_points, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_tensor)\n",
    "        probabilities = torch.exp(outputs)\n",
    "        predicted_labels = outputs.argmax(dim=1).cpu().numpy()\n",
    "        scores = probabilities.max(dim=1)[0].cpu().numpy()\n",
    "\n",
    "    # Формирование списка баундинг-боксов для всех ячеек в батче\n",
    "    bboxes = []\n",
    "    for i, (idx, center_local, cell_points_sampled) in enumerate(batch_indices):\n",
    "        if scores[i] >= score_threshold:\n",
    "            size_x = max(np.ptp(cell_points_sampled[:, 0]), 0.1)\n",
    "            size_y = max(np.ptp(cell_points_sampled[:, 1]), 0.1)\n",
    "            size_z = max(np.ptp(cell_points_sampled[:, 2]), 0.1)\n",
    "            \n",
    "            # Вычисление yaw\n",
    "            yaw = calculate_yaw(cell_points_sampled)\n",
    "            \n",
    "            bbox = {\n",
    "                'file_name': file_name,\n",
    "                'center_x': center_local[0],\n",
    "                'center_y': center_local[1],\n",
    "                'center_z': center_local[2],\n",
    "                'size_x': size_x,\n",
    "                'size_y': size_y,\n",
    "                'size_z': size_z,\n",
    "                'yaw': yaw,\n",
    "                'class': label_encoder.inverse_transform([predicted_labels[i]])[0],\n",
    "                'score': scores[i]\n",
    "            }\n",
    "            bboxes.append(bbox)\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "# Обработка тестового файла\n",
    "def process_test_file(file_name, test_dir, model, label_encoder, num_points, device, score_threshold=0.5, grid_size=10.0):\n",
    "    file_path = os.path.join(test_dir, file_name)\n",
    "    bbox_list = []\n",
    "\n",
    "    # Загрузка точек из файла\n",
    "    las = laspy.read(file_path)\n",
    "    points_global = las.xyz.astype(np.float32)\n",
    "\n",
    "    # Преобразование в локальные координаты\n",
    "    offsets = np.array(las.header.offsets, dtype=np.float32)\n",
    "    points = points_global - offsets\n",
    "\n",
    "    del las, points_global\n",
    "    gc.collect()\n",
    "\n",
    "    # Разделение точек на ячейки\n",
    "    indices = np.floor(points / grid_size).astype(np.int32)\n",
    "    unique_indices, inverse_indices = np.unique(indices, axis=0, return_inverse=True)\n",
    "\n",
    "    # Группировка точек по ячейкам\n",
    "    cell_points_dict = defaultdict(list)\n",
    "    for idx, point in zip(inverse_indices, points):\n",
    "        cell_points_dict[idx].append(point)\n",
    "\n",
    "    # Параллельная обработка ячеек\n",
    "    pbar = tqdm(total=len(cell_points_dict), desc=f\"Обработка ячеек в файле {file_name}\")\n",
    "    results = []\n",
    "    for idx in cell_points_dict.keys():\n",
    "        result = process_cells_in_batch(\n",
    "            {idx: cell_points_dict[idx]},\n",
    "            file_name,\n",
    "            label_encoder,\n",
    "            score_threshold,\n",
    "            model,\n",
    "            device,\n",
    "            num_points\n",
    "        )\n",
    "        results.extend(result)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    bbox_list.extend(results)\n",
    "    return bbox_list\n",
    "\n",
    "# Обработка всех тестовых файлов\n",
    "def predict_and_combine(test_dir, model, output_csv, label_encoder, num_points=512, score_threshold=0.5, grid_size=5.0, min_size_z=1.0):\n",
    "    model.eval()\n",
    "    test_files = [f for f in os.listdir(test_dir) if f.endswith('.las')]\n",
    "    combined_results = []\n",
    "    current_id = 1\n",
    "\n",
    "    for file_name in tqdm(test_files, desc=\"Обработка тестовых файлов\"):\n",
    "        with torch.no_grad():\n",
    "            bbox_list = process_test_file(\n",
    "                file_name, test_dir, model, label_encoder, num_points, DEVICE, score_threshold, grid_size\n",
    "            )\n",
    "\n",
    "        # Применяем постобработку, не обрабатываем объекты менее заданной высоты\n",
    "        filtered_bboxes = []\n",
    "        for bbox in bbox_list:\n",
    "            if bbox['size_z'] < min_size_z:\n",
    "                continue\n",
    "\n",
    "            bbox['id'] = current_id  # Уникальный ID\n",
    "            filtered_bboxes.append(bbox)\n",
    "            current_id += 1\n",
    "\n",
    "        combined_results.extend(filtered_bboxes)\n",
    "\n",
    "    # Проверяем, есть ли результаты\n",
    "    if combined_results:\n",
    "        combined_df = pd.DataFrame(combined_results)\n",
    "        columns = ['id', 'file_name', 'center_x', 'center_y', 'center_z',\n",
    "                   'size_x', 'size_y', 'size_z', 'yaw', 'class', 'score']\n",
    "        combined_df = combined_df[columns]\n",
    "        combined_df.to_csv(output_csv, index=False)\n",
    "        print(f\"Результаты сохранены в {output_csv}\")\n",
    "    else:\n",
    "        print(\"Нет результатов для сохранения.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7fce94a-e185-40ef-a1cc-82d17a27057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagi\\AppData\\Local\\Temp\\ipykernel_11048\\1211678664.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_imppointnet_model4_epoch_19.pth', map_location=DEVICE), strict=False)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "model = PointNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load('PointNetPP_epoch_10.pth', map_location=DEVICE), strict=False)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Установка параметров постобработки\n",
    "min_size_z = 1.0  # Минимальный размер объекта по оси Z\n",
    "\n",
    "# Запуск предсказания\n",
    "predict_and_combine_optimized(test_dir=TEST_DIR,\n",
    "                    model=model,\n",
    "                    output_csv=OUTPUT_CSV,\n",
    "                    label_encoder=label_encoder,\n",
    "                    num_points=512,\n",
    "                    score_threshold=0.5,\n",
    "                    grid_size=10.0,\n",
    "                    min_size_z=min_size_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048a0c7-25f8-4e8b-852c-c01e9a843b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda123",
   "language": "python",
   "name": "pytorch_cuda123"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
